{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategoriler ve veri dizini\n",
    "KATEGORILER = [\"cardboard\", \"glass\", \"metal\", \"paper\", \"plastic\", \"trash\"]\n",
    "DIR = \"/content/gdrive/MyDrive/Colab Notebooks/garbage_dataset/Garbage_classification/Garbage_classification\"\n",
    "BOYUT = 64\n",
    "\n",
    "# Veriyi saklamak için liste\n",
    "veri = []\n",
    "\n",
    "# Veri yükleme ve işleme\n",
    "for kategori in KATEGORILER:\n",
    "    klasor_adresi = os.path.join(DIR, kategori)\n",
    "    deger = KATEGORILER.index(kategori)\n",
    "    for resim_adi in tqdm(os.listdir(klasor_adresi)):\n",
    "        resim_adresi = os.path.join(klasor_adresi, resim_adi)\n",
    "        resim = cv2.imread(resim_adresi, cv2.IMREAD_COLOR)\n",
    "        if resim is None:\n",
    "            print(\"hata\")\n",
    "        else:\n",
    "            resim = cv2.resize(resim, (BOYUT, BOYUT))\n",
    "            veri.append([resim, deger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi karıştırarak modelin daha iyi öğrenmesini sağlama\n",
    "random.shuffle(veri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giriş ve çıkış verileri için listeler\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Veriyi ayrıştırma\n",
    "for x, y in veri:\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "\n",
    "del veri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi numpy dizilerine dönüştürme\n",
    "X = np.array(X).reshape(-1, BOYUT, BOYUT, 3)\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi normalleştirme\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi eğitim ve doğrulama kümelerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giriş katmanı oluşturma\n",
    "giris = Input(shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evrişimli katmanlar\n",
    "conv1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(giris)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(64, kernel_size=(3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "# Düzleştirme katmanı\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Tam bağlantı katmanları\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "output = Dense(6, activation='softmax')(dense1)\n",
    "\n",
    "# Modeli oluşturma\n",
    "model = Model(inputs=giris, outputs=output)\n",
    "\n",
    "# Model özetini görüntüleme\n",
    "model.summary()\n",
    "\n",
    "# Modeli derleme\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "\n",
    "# Aşırı öğrenmeyi engellemek için \n",
    "model_checkpoint = ModelCheckpoint('model.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, mode='max')\n",
    "\n",
    "# Modeli eğitme\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test), callbacks=[early_stopping, model_checkpoint])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
